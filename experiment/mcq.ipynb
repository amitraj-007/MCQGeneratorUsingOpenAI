{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(openai_api_key=key,model_name=\"gpt-3.5-turbo\",temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023ECD331100>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023EAA0B6090>, root_client=<openai.OpenAI object at 0x0000023EA9F504A0>, root_async_client=<openai.AsyncOpenAI object at 0x0000023ECD331160>, temperature=0.5, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be confirming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_14648\\1121590683.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n"
     ]
    }
   ],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"D:\\mcqgenerator\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\mcqgenerator\\\\data.txt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is LangChain?\n",
      "LangChain is a framework designed to build applications powered by Large Language Models (LLMs), such as OpenAI's GPT-3.5 or GPT-4. It provides tools, abstractions, and integrations that make it easier to create applications like chatbots, question-answering systems, summarization tools, and more.\n",
      "\n",
      "LangChain's core philosophy is modularity and chainability, meaning it helps developers break down complex workflows into smaller, manageable, and reusable components.\n",
      "\n",
      "Key Components of LangChain\n",
      "LLMs (Large Language Models):\n",
      "\n",
      "LangChain supports multiple LLMs (e.g., OpenAI, Hugging Face, Cohere).\n",
      "It provides wrappers to interact with these models and configure parameters like temperature, model_name, and max_tokens.\n",
      "Prompts:\n",
      "\n",
      "LangChain offers tools to manage, format, and template prompts effectively.\n",
      "You can define reusable prompt templates and dynamically inject variables.\n",
      "Example:\n",
      "\n",
      "python\n",
      "Copy\n",
      "Edit\n",
      "from langchain.prompts import PromptTemplate\n",
      "\n",
      "template = \"Translate the following text to French: {text}\"\n",
      "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
      "Chains:\n",
      "\n",
      "Chains allow you to link multiple steps in a pipeline.\n",
      "For example, a chain might take a userâ€™s query, call an LLM to process it, and then store the result in a database.\n",
      "Types of Chains:\n",
      "\n",
      "Simple Chains: Sequentially process inputs and outputs.\n",
      "Sequential Chains: Combine multiple chains in sequence.\n",
      "Memory Chains: Keep context across multiple calls, useful for chatbots.\n",
      "Example:\n",
      "\n",
      "python\n",
      "Copy\n",
      "Edit\n",
      "from langchain.chains import LLMChain\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "\n",
      "llm = ChatOpenAI(temperature=0.7)\n",
      "prompt = PromptTemplate(template=\"What's the capital of {country}?\", input_variables=[\"country\"])\n",
      "chain = LLMChain(llm=llm, prompt=prompt)\n",
      "\n",
      "result = chain.run({\"country\": \"France\"})\n",
      "print(result)  # \"Paris\"\n",
      "Memory:\n",
      "\n",
      "Memory is used to store the state of a conversation or process.\n",
      "Example: Keeping track of previous questions and answers in a chatbot.\n",
      "Types:\n",
      "\n",
      "Short-Term Memory: Used for recent interactions.\n",
      "Long-Term Memory: Persistent memory for long-term context.\n",
      "Example:\n",
      "\n",
      "python\n",
      "Copy\n",
      "Edit\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "\n",
      "memory = ConversationBufferMemory()\n",
      "Agents:\n",
      "\n",
      "Agents dynamically decide which action to take based on user input and available tools.\n",
      "Example: A chatbot that can perform calculations, retrieve documents, or generate text.\n",
      "Example Agent Workflow:\n",
      "\n",
      "Input: \"What's 2+2?\"\n",
      "Agent decides to call a calculator tool.\n",
      "Output: \"4\"\n",
      "Tools:\n",
      "\n",
      "Tools are external utilities that the LLM can use.\n",
      "Examples:\n",
      "Calculators\n",
      "Search engines\n",
      "Custom APIs\n",
      "Tools can be combined with agents to build dynamic systems.\n",
      "Example:\n",
      "\n",
      "python\n",
      "Copy\n",
      "Edit\n",
      "from langchain.agents import load_tools\n",
      "tools = load_tools([\"serpapi\", \"llm-math\"])\n",
      "Retrievers and Vector Stores:\n",
      "\n",
      "LangChain supports integration with vector databases (e.g., Pinecone, Weaviate, FAISS) to retrieve relevant documents.\n",
      "Useful for building question-answering systems with large datasets.\n",
      "Why Use LangChain?\n",
      "Modularity:\n",
      "\n",
      "Break your application into manageable components.\n",
      "Reuse components across multiple projects.\n",
      "Ease of Integration:\n",
      "\n",
      "LangChain integrates with popular LLM providers, databases, APIs, and tools.\n",
      "Support for Complex Workflows:\n",
      "\n",
      "Build applications that involve multiple steps, dynamic decisions, or memory.\n",
      "Built-in Memory:\n",
      "\n",
      "Enables conversational agents to retain context.\n",
      "Rich Ecosystem:\n",
      "\n",
      "Plug-and-play support for many tools like search engines, calculators, APIs, and more.\n",
      "LangChain Ecosystem\n",
      "LLM Providers:\n",
      "\n",
      "OpenAI (e.g., GPT-3.5, GPT-4)\n",
      "Hugging Face models\n",
      "Cohere, Anthropic, and more.\n",
      "Vector Databases:\n",
      "\n",
      "Pinecone, Weaviate, FAISS, and Chroma for document retrieval and embeddings.\n",
      "Tool Integration:\n",
      "\n",
      "Google Search (via SerpAPI)\n",
      "Python REPL\n",
      "WolframAlpha\n",
      "Custom APIs.\n",
      "Frameworks:\n",
      "\n",
      "Works well with Python, but also supports JavaScript/TypeScript.\n",
      "Common Use Cases\n",
      "Chatbots:\n",
      "\n",
      "Build conversational agents with memory and tool integrations.\n",
      "Document QA:\n",
      "\n",
      "Answer questions from documents by retrieving and summarizing content.\n",
      "Summarization:\n",
      "\n",
      "Summarize long texts or documents into concise formats.\n",
      "Code Assistance:\n",
      "\n",
      "Use agents to write, debug, or analyze code.\n",
      "Custom Workflows:\n",
      "\n",
      "Build domain-specific applications like legal advisors, customer support bots, or creative writing assistants.\n",
      "Installation\n",
      "To get started with LangChain:\n",
      "\n",
      "bash\n",
      "Copy\n",
      "Edit\n",
      "pip install langchain\n",
      "pip install openai  # For OpenAI integrations\n",
      "Basic Example\n",
      "Hereâ€™s a simple chatbot example using LangChain:\n",
      "\n",
      "python\n",
      "Copy\n",
      "Edit\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.chains import ConversationChain\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "\n",
      "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
      "memory = ConversationBufferMemory()\n",
      "\n",
      "chatbot = ConversationChain(llm=llm, memory=memory)\n",
      "\n",
      "response = chatbot.run(\"Hello, how can I assist you?\")\n",
      "print(response)\n"
     ]
    }
   ],
   "source": [
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the Python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"openAI\"\n",
    "TONE=\"Simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_14648\\2654919708.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response=generate_evaluate_chain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:OpenAI is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. Its stated mission is to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".[5] As a leading organization in the ongoing AI boom,[6] OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora.[7][8] Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI.\n",
      "\n",
      "The organization consists of the non-profit OpenAI, Inc.,[9] registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC.[10] Microsoft owns roughly 49% of OpenAI's equity, having invested US$13 billion.[11] It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure.[12]\n",
      "\n",
      "In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI's products. In November 2023, OpenAI's board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company's prominent role in an industry-wide problem.[13][14]\n",
      "\n",
      "History\n",
      "2015â€“2018: Non-profit beginnings\n",
      "\n",
      "Former headquarters at the Pioneer Building in San Francisco\n",
      "In December 2015, OpenAI was founded by Sam Altman, Elon Musk, Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk as the co-chairs. A total of $1 billion in capital was pledged by Sam Altman, Greg Brockman, Elon Musk, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), Infosys, and YC Research.[15][16] The actual collected total amount of contributions was only $130 million until 2019.[10] According to an investigation led by TechCrunch, Musk was its largest donor while YC Research did not contribute anything at all.[17] The organization stated it would \"freely collaborate\" with other institutions and researchers by making its patents and research open to the public.[18][19] OpenAI was initially run from Brockman's living room.[20] It was later headquartered at the Pioneer Building in the Mission District, San Francisco.[21][22]\n",
      "\n",
      "According to Wired, Brockman met with Yoshua Bengio, one of the \"founding fathers\" of deep learning, and drew up a list of the \"best researchers in the field\".[23] Brockman was able to hire nine of them as the first employees in December 2015.[23] In 2016, OpenAI paid corporate-level (rather than nonprofit-level) salaries, but did not pay AI researchers salaries comparable to those of Facebook or Google.[23]\n",
      "\n",
      "Microsoft's Peter Lee stated that the cost of a top AI researcher exceeds the cost of a top NFL quarterback prospect.[23] OpenAI's potential and mission drew these researchers to the firm; a Google employee said he was willing to leave Google for OpenAI \"partly because of the very strong group of people and, to a very large extent, because of its mission.\"[23] Brockman stated that \"the best thing that I could imagine doing was moving humanity closer to building real AI in a safe way.\"[23] OpenAI co-founder Wojciech Zaremba stated that he turned down \"borderline crazy\" offers of two to three times his market value to join OpenAI instead.[23]\n",
      "\n",
      "In April 2016, OpenAI released a public beta of \"OpenAI Gym\", its platform for reinforcement learning research.[24] Nvidia gifted its first DGX-1 supercomputer to OpenAI in August 2016 to help it train larger and more complex AI models with the capability of reducing processing time from six days to two hours.[25][26] In December 2016, OpenAI released \"Universe\", a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites, and other applications.[27][28][29][30]\n",
      "\n",
      "In 2017, OpenAI spent $7.9 million, or a quarter of its functional expenses, on cloud computing alone.[31] In comparison, DeepMind's total expenses in 2017 were $442 million. In the summer of 2018, simply training OpenAI's Dota 2 bots required renting 128,000 CPUs and 256 GPUs from Google for multiple weeks.\n",
      "\n",
      "In 2018, Musk resigned from his Board of Directors seat, citing \"a potential future conflict [of interest]\" with his role as CEO of Tesla due to Tesla's AI development for self-driving cars.[32] Sam Altman claims that Musk believed that OpenAI had fallen behind other players like Google and Musk proposed instead to take over OpenAI himself, which the board rejected. Musk subsequently left OpenAI.\n",
      "\n",
      "In February 2019, GPT-2 was announced, which gained attention for its ability to generate human-like text.[33]\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for openAI students in Simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be confirming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:OpenAI is an American artificial intelligence (AI) research organization founded in December 2015 and headquartered in San Francisco, California. Its stated mission is to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".[5] As a leading organization in the ongoing AI boom,[6] OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image models, and a text-to-video model named Sora.[7][8] Its release of ChatGPT in November 2022 has been credited with catalyzing widespread interest in generative AI.\n",
      "\n",
      "The organization consists of the non-profit OpenAI, Inc.,[9] registered in Delaware, and its for-profit subsidiary introduced in 2019, OpenAI Global, LLC.[10] Microsoft owns roughly 49% of OpenAI's equity, having invested US$13 billion.[11] It also provides computing resources to OpenAI through its cloud platform, Microsoft Azure.[12]\n",
      "\n",
      "In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media companies whose work was used to train some of OpenAI's products. In November 2023, OpenAI's board removed Sam Altman as CEO, citing a lack of confidence in him, but reinstated him five days later following a reconstruction of the board. Throughout 2024, roughly half of then-employed AI safety researchers left OpenAI, citing the company's prominent role in an industry-wide problem.[13][14]\n",
      "\n",
      "History\n",
      "2015â€“2018: Non-profit beginnings\n",
      "\n",
      "Former headquarters at the Pioneer Building in San Francisco\n",
      "In December 2015, OpenAI was founded by Sam Altman, Elon Musk, Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk as the co-chairs. A total of $1 billion in capital was pledged by Sam Altman, Greg Brockman, Elon Musk, Reid Hoffman, Jessica Livingston, Peter Thiel, Amazon Web Services (AWS), Infosys, and YC Research.[15][16] The actual collected total amount of contributions was only $130 million until 2019.[10] According to an investigation led by TechCrunch, Musk was its largest donor while YC Research did not contribute anything at all.[17] The organization stated it would \"freely collaborate\" with other institutions and researchers by making its patents and research open to the public.[18][19] OpenAI was initially run from Brockman's living room.[20] It was later headquartered at the Pioneer Building in the Mission District, San Francisco.[21][22]\n",
      "\n",
      "According to Wired, Brockman met with Yoshua Bengio, one of the \"founding fathers\" of deep learning, and drew up a list of the \"best researchers in the field\".[23] Brockman was able to hire nine of them as the first employees in December 2015.[23] In 2016, OpenAI paid corporate-level (rather than nonprofit-level) salaries, but did not pay AI researchers salaries comparable to those of Facebook or Google.[23]\n",
      "\n",
      "Microsoft's Peter Lee stated that the cost of a top AI researcher exceeds the cost of a top NFL quarterback prospect.[23] OpenAI's potential and mission drew these researchers to the firm; a Google employee said he was willing to leave Google for OpenAI \"partly because of the very strong group of people and, to a very large extent, because of its mission.\"[23] Brockman stated that \"the best thing that I could imagine doing was moving humanity closer to building real AI in a safe way.\"[23] OpenAI co-founder Wojciech Zaremba stated that he turned down \"borderline crazy\" offers of two to three times his market value to join OpenAI instead.[23]\n",
      "\n",
      "In April 2016, OpenAI released a public beta of \"OpenAI Gym\", its platform for reinforcement learning research.[24] Nvidia gifted its first DGX-1 supercomputer to OpenAI in August 2016 to help it train larger and more complex AI models with the capability of reducing processing time from six days to two hours.[25][26] In December 2016, OpenAI released \"Universe\", a software platform for measuring and training an AI's general intelligence across the world's supply of games, websites, and other applications.[27][28][29][30]\n",
      "\n",
      "In 2017, OpenAI spent $7.9 million, or a quarter of its functional expenses, on cloud computing alone.[31] In comparison, DeepMind's total expenses in 2017 were $442 million. In the summer of 2018, simply training OpenAI's Dota 2 bots required renting 128,000 CPUs and 256 GPUs from Google for multiple weeks.\n",
      "\n",
      "In 2018, Musk resigned from his Board of Directors seat, citing \"a potential future conflict [of interest]\" with his role as CEO of Tesla due to Tesla's AI development for self-driving cars.[32] Sam Altman claims that Musk believed that OpenAI had fallen behind other players like Google and Musk proposed instead to take over OpenAI himself, which the board rejected. Musk subsequently left OpenAI.\n",
      "\n",
      "In February 2019, GPT-2 was announced, which gained attention for its ability to generate human-like text.[33]\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for openAI students in Simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be confirming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:3453\n",
      "Prompt Tokens:2782\n",
      "Completion Tokens:671\n",
      "Total Cost:0.0023975000000000003\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "\"1\": {\n",
      "\"mcq\": \"When was OpenAI founded?\",\n",
      "\"options\": {\n",
      "\"a\": \"2010\",\n",
      "\"b\": \"2015\",\n",
      "\"c\": \"2020\",\n",
      "\"d\": \"2025\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"2\": {\n",
      "\"mcq\": \"Who are the co-chairs of OpenAI?\",\n",
      "\"options\": {\n",
      "\"a\": \"Sam Altman and Elon Musk\",\n",
      "\"b\": \"Greg Brockman and Trevor Blackwell\",\n",
      "\"c\": \"Ilya Sutskever and Andrej Karpathy\",\n",
      "\"d\": \"John Schulman and Wojciech Zaremba\"\n",
      "},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"3\": {\n",
      "\"mcq\": \"Which AI model gained attention for its ability to generate human-like text?\",\n",
      "\"options\": {\n",
      "\"a\": \"DALL-E\",\n",
      "\"b\": \"Sora\",\n",
      "\"c\": \"GPT-2\",\n",
      "\"d\": \"ChatGPT\"\n",
      "},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"4\": {\n",
      "\"mcq\": \"Who invested US$13 billion in OpenAI and owns roughly 49% of its equity?\",\n",
      "\"options\": {\n",
      "\"a\": \"Elon Musk\",\n",
      "\"b\": \"Sam Altman\",\n",
      "\"c\": \"Microsoft\",\n",
      "\"d\": \"Reid Hoffman\"\n",
      "},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"5\": {\n",
      "\"mcq\": \"In what year did OpenAI release a public beta of 'OpenAI Gym'?\",\n",
      "\"options\": {\n",
      "\"a\": \"2015\",\n",
      "\"b\": \"2016\",\n",
      "\"c\": \"2017\",\n",
      "\"d\": \"2018\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "quiz=response.get(\"quiz\")\n",
    "print(quiz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"machinelearning.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01_22_2025_21_08_45'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m_%d_%Y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\mcqgenerator\\env\\Library\\ssl\\cacert.pem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ.get(\"SSL_CERT_FILE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
